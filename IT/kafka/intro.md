### Зачем кафка?

https://www.youtube.com/playlist?list=PLt91xr-Pp57Q50WsXz9r-zmxy5ceu_hp_

- отправка сообщений сразу многим получателям
- нет потери сообщений если получатель недоступен
- добавления получателя не требует доработки отправителя

В случае, если используется REST, сообщения отправляются напрямую.

С кафкой сообщения сначала публикуются в кафка топик и уже из топика другие 
сервисы считывают сообщения.

Тот кто публикует сообщения называется Producer или Publisher, а те кто 
читают сообщения называется Consumer или Subscriber.

Producer не знает о Consumer, а Consumer про Producer.

Это позволяется добавлять Consumer при этом не делать изменения в Producer.

Это называется Event Driver Architecture - события публикуются, что 
явлляется триггером для дальнейших действий.

 - Асинхронное взаимодействие
 - Слабые связи
 - Гибкость изменений
 - Легкое масштабирование
 - Consumer пожет обработать сообзения после восстановления
 - Producer не ждет отбработки, не знает про то, кто обрабатывает

Kafka Broker - сервер, который получает сообщение от producer и сохраняте 
сообщение на диске, после чего передает его в consumer. 

Каждый broker отвечает за управление одним или несколькими topic, которые 
разделены на partition для распределения даннных. Каждый новый event 
сохраняется в partition.
Broker выполняют важную роль в обеспечении отказоустойчивости и 
масштабируемости в Kafka.
```

                               Kafka Cluster
+—————————————————————————————————————————————————————————————————————————+
|                                                                         |
|                                Broker                                   |
|   +—————————————————————————————————————————————————————————————————+   |
|   |                                                                 |   |
|   |             Topic                            Topic              |   |
|   |   +—————————————————————————+     +—————————————————————————+   |   |
|   |   |                         |     |                         |   |   |
|   |   |        Partition        |     |       Partition         |   |   |
|   |   |    +——————————————+     |     |    +——————————————+     |   |   |
|   |   |    |    |    |    |     |     |    |    |    |    |     |   |   |
|   |   |    |————|————|————|     |     |    |————|————|————|     |   |   |
|   |   |    |    |    |    |     |     |    |    |    |    |     |   |   |
|   |   |    |————|————|————|     |     |    |————|————|————|     |   |   |
|   |   |    |    |    |    |     |     |    |    |    |    |     |   |   |
|   |   |    +——————————————+     |     |    +——————————————+     |   |   |
|   |   |                         |     |                         |   |   |
|   |   +—————————————————————————+     +—————————————————————————+   |   |
|   |                                                                 |   |
|   +—————————————————————————————————————————————————————————————————+   |
|                                                                         |
+—————————————————————————————————————————————————————————————————————————+

```



Kafka cluster - несколько broker синхронизированных между собой.

Kafka event - название состоит из названия сущности над которой происходит 
действие + название действия + постфикс event.

Topic - к нему подключаются consumer и читают сообщения. Состоит из 
partition, event из partition читаются по порядку.

Offset - partition index.

Event добавляется в конец partition
Event нельзя изменить или удалить.

По умолчания topic настроен на хранение events в течении 7 дней, но можно 
изменить.
Даже после прочтения event он продолжает хранится еще 7 дней.

Изначально event распределяются между partitions, а consumer читает 
event паралельно, то есть не гарантируется очередность чтения из partition.

Если отправлять event с одинаковым key то они будут попадать в одну partition.

Message состоит из
- Key(message id)
- Event (message value)
- Timestamp (creation time)
- Headers (optional, ex: auth header)

---
# Kafka

https://www.youtube.com/watch?v=-AZOi3kP9Js&t=1s&ab_channel=%D0%92%D0%BB%D0%B0%D0%B4%D0%B8%D0%BC%D0%B8%D1%80%D0%91%D0%BE%D0%B3%D0%B4%D0%B0%D0%BD%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9


Сложность передачи данных:
- надежность и гарантия доставки
- подключение новых получателей
- отпраители знают получателей
- техническая поддержка
- интеграции разных стеков


Решение: использовать посредника, брокера сообщений, который примет функцию 
получения и предоставления данных.

Удобства:
- надежность и гарантия доставки
- подключение новых получателей
- отправители не знают получателей
- тезническая поддержка
- интеграции разных стеков

Kafka performance

Why is it so fast?
- Scalable arcgitecture
- Sequential write and read
- No random read
- Zero-copy
- Huge amount of settings for different cases

---

### Основные сущности Кафки
- broker
- cluster
- zookeeper
- message (record)
- topic/partition
- producer
- consumer

---

### Broker (Kafka Server / Kafka Node)

Функции:
- прием сообщений
- хранение сообщений
- выдача сообщений

Создаются несколько брокеров для надежности и производительности.
Брокеры могут общаться между собой образуя кластер. Это нужно для надежности 
хранения данных.

---

### Zookeeper

Хранилище, небольшая база данных, которая быстро работает на чтение и не 
очень быстро на запись. 
Используется для:
- хранения метаданых
- состояний кластера
- конфигурация
- информация о брокерах
- партиции итд.

---

### Message (Record / Event)

Состоит из:
- key ( ключ, который используется для распределения сообщений по сластеру )
- value ( содержимое сообщения - массив байт )
- timestamp ( время сообщения. устанавливается при отправке/обработке внутри кластера )
- headers  ( набор key-value с пользовательскими отрибутами сообщения )

---

### Topic / Partitions

Основная сущность кафки, стрим данных. Сообщения можно складывать в топик в 
очередь откуда сообщения извлекаются. 

Сообщения при чтении не удаляются из топика, это позволяет чтение сообщений 
несколькими получаетлями.

Плохо работает при больших нагрузках.

В итоге, одна очередь в топике была разделена на партиции. ( конфигурируемый параметер )
Нужны для распараллеливание нагрузки.
Ускоряют чтение/запись данных.

Сообщения отправляются в топик, сообщения распределяются по партициям, 
потребитиль читает сообщения, не в порядке в котором они были отправлены 
продюсером, а в порядке в котором лежат в партиции.

Чтоб сохранить очередность чтения сообщений, сообщения нужно отправлять с 
одинаковым ключем, тогда они будут помещены в одну партицию.

Топик размещен в нескольких брокерах, партиции распределяются по брокерам.

Данные хранятся в log файлах.

Есть папка logs, в ней есть папки с названием имя топик + номер партиции

В каждой папке партиции есть файлы: которые могут повторяться
- 001.log - хранит сообщение 
    - Offset - номер сообщения в партиции
    - Position - позиция сообщения в байтах
    - Timestamp
    - Message
- 001.index - маппинг offset на position
- 001.timeindex - маппинг timestamp на offset

У .log есть лимит, по дефолту 1гб. При заполнении файла создаются новые 
файлы .log, .index, .timeindex. Это называют Segments.

---

### Удаление

Операция ручного удаления сообщений в kafka topic не поддерживатеся.
Есть автоматическое удаление по TTL( time to live ). Удаляются не сообщение, 
а сегменты.
Сегменты удаляются при истечении срока жизни сегмента.

---

### Data replication

Надежность данныз и отказоустойчивость.

Есть Topic A с тремя партициями. Партиции распределены по брокерам.
В случае  падения одного из брокеров, мы теряем данные из партиции которая 
находилась в брокере.

Чтоб этого избежать введена репликация, для каждой партиции есть ее реплика 
в другом брокере. Реплики одной партиции не могут находиться в одном брокере.


---

### Master-Slave

Кафка обеспечивает согласованность данных. Данные не могут теряться, меняться.

Для этого одна из реплик партиции назначается leader, все остальные 
называются follower. 

Kafka Controller назначает Leader реплику.

Операции Чтения и записи производятся только с Leader репликой.
```
Producer ---> Leader ---> Consumer
```

---

### Producer

Kafka Producer - высокопроизводительный отправитель сообщений

У producer есть функция send с параметрами:
- acks - гарантия доставки
    - 0 - producer не ждет подтверждения отправки сообщений. Это самый 
      ненадежный режим, сообщения могут теряться.
    - 1 - producer ждет подтверждения только от Leader реплики. Могут 
      теряться сообщения если брокер с Leader репликой упал до того, как 
      сообщения реплицировалось.
    - -1 (all) - producer ждет подтверждения отправки сообщений от реплик 
      Leader и ISR. В этом случае сообщения не теряются.

Порядок действий:

```
Producer(send) -> fetch metadata -> serialize message -> define partition --+
                                                                            |
   send to broker and partitions <- accumulate batch <- compress message <--+
```

---

### Consumer

Kafka Consumer - высокопроизводительный получатель сообщений



